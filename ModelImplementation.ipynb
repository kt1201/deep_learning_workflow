{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ModelImplementation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"00MVx5LSEk-J","colab_type":"text"},"source":["*   bottleneck_support.py\n","\n"]},{"cell_type":"code","metadata":{"id":"LCSVF4n_Epqj","colab_type":"code","colab":{}},"source":["import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PST-Co8CEt1t","colab_type":"code","colab":{}},"source":["input_size = 10\n","epochs = 2\n","batches = 64\n","lr = 0.01"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"udcNJQ_FEwVy","colab_type":"code","colab":{}},"source":["def encoder(input_size):\n","    def wrapper(num):\n","        ret = [int(i) for i in '{0:b}'.format(num)]\n","        return [0] * (input_size - len(ret)) + ret\n","    return wrapper\n","\n","\n","def decoder(array):\n","    ret = 0\n","    for i in array:\n","        ret = ret * 2 + int(i)\n","    return ret\n","\n","\n","def training_test_gen(x, y):\n","    assert len(x) == len(y)\n","    indices = np.random.permutation(range(len(x)))\n","    split_size = int(0.9 * len(indices))\n","    trX = x[indices[:split_size]]\n","    trY = y[indices[:split_size]]\n","    teX = x[indices[split_size:]]\n","    teY = y[indices[split_size:]]\n","    return trX, trY, teX, teY\n","\n","\n","def get_data(input_size):\n","    x = []\n","    y = []\n","    binary_enc = encoder(input_size)\n","    for i in range(1000):\n","        x.append(binary_enc(i))\n","        if i % 15 == 0:\n","            y.append([1, 0, 0, 0])\n","        elif i % 5 == 0:\n","            y.append([0, 1, 0, 0])\n","        elif i % 3 == 0:\n","            y.append([0, 0, 1, 0])\n","        else:\n","            y.append([0, 0, 0, 1])\n","    return training_test_gen(np.array(x), np.array(y))\n","\n","\n","def check_fizbuz(i):\n","    if i % 15 == 0:\n","        return 'fizbuz'\n","    elif i % 5 == 0:\n","        return 'buz'\n","    elif i % 3 == 0:\n","        return 'fiz'\n","    else:\n","        return 'number'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ray4FEK3ExZj","colab_type":"code","colab":{}},"source":["class FizBuzNet(nn.Module):\n","\n","    def __init__(self, input_size, output_size):\n","        super(FizBuzNet, self).__init__()\n","        # A simple heuristic to find the hiddenlayer size\n","        hidden_size = 100\n","        self.hidden = nn.Linear(input_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, batch):\n","        hidden = self.hidden(batch)\n","        activated = F.sigmoid(hidden)\n","        out = self.out(activated)\n","        return F.sigmoid(out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GN3lgvP9FC-B","colab_type":"code","outputId":"f50183d4-ee02-407b-88cf-f68ab6b537b2","executionInfo":{"status":"ok","timestamp":1576071325760,"user_tz":-540,"elapsed":581,"user":{"displayName":"김기태","photoUrl":"","userId":"05611496824164447321"}},"colab":{"base_uri":"https://localhost:8080/","height":721}},"source":["trX, trY, teX, teY = get_data(input_size)\n","if torch.cuda.is_available():\n","    dtype = torch.cuda.FloatTensor\n","else:\n","    dtype = torch.FloatTensor\n","x = torch.from_numpy(trX).type(dtype)\n","y = torch.from_numpy(trY).type(dtype)\n","\n","net = FizBuzNet(input_size, 4)\n","net = net.to(device)\n","loss_fn = nn.MSELoss()\n","optimizer = optim.Adam(net.parameters(), lr=lr)\n","x_ = x[0:10]\n","y_ = y[0:10]\n","\n","with torch.autograd.profiler.profile() as prof:\n","    hyp = net(x_)\n","\n","print(prof)\n","prof.export_chrome_trace('chrometrace')\n","print(prof.key_averages())\n","print(prof.table('cpu_time'))\n","\n","\n","loss = loss_fn(hyp, y_)\n","loss.backward()\n","optimizer.step()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n","Name                Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  Input Shapes                         \n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n","unsigned short      7.30%            28.984us         7.30%            28.984us         28.984us         NaN              0.000us          0.000us          1                []                                   \n","addmm               45.00%           178.746us        45.00%           178.746us        178.746us        NaN              0.000us          0.000us          1                []                                   \n","sigmoid             19.72%           78.347us         19.72%           78.347us         78.347us         NaN              0.000us          0.000us          1                []                                   \n","unsigned short      2.78%            11.056us         2.78%            11.056us         11.056us         NaN              0.000us          0.000us          1                []                                   \n","addmm               15.15%           60.173us         15.15%           60.173us         60.173us         NaN              0.000us          0.000us          1                []                                   \n","sigmoid             10.05%           39.911us         10.05%           39.911us         39.911us         NaN              0.000us          0.000us          1                []                                   \n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n","Self CPU time total: 397.217us\n","CUDA time total: 0.000us\n","\n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n","Name                Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  \n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n","unsigned short      10.08%           40.040us         10.08%           40.040us         20.020us         NaN              0.000us          0.000us          2                \n","addmm               60.15%           238.919us        60.15%           238.919us        119.460us        NaN              0.000us          0.000us          2                \n","sigmoid             29.77%           118.258us        29.77%           118.258us        59.129us         NaN              0.000us          0.000us          2                \n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n","Self CPU time total: 397.217us\n","CUDA time total: 0.000us\n","\n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n","Name                Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  Input Shapes                         \n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n","addmm               45.00%           178.746us        45.00%           178.746us        178.746us        NaN              0.000us          0.000us          1                []                                   \n","sigmoid             19.72%           78.347us         19.72%           78.347us         78.347us         NaN              0.000us          0.000us          1                []                                   \n","addmm               15.15%           60.173us         15.15%           60.173us         60.173us         NaN              0.000us          0.000us          1                []                                   \n","sigmoid             10.05%           39.911us         10.05%           39.911us         39.911us         NaN              0.000us          0.000us          1                []                                   \n","unsigned short      7.30%            28.984us         7.30%            28.984us         28.984us         NaN              0.000us          0.000us          1                []                                   \n","unsigned short      2.78%            11.056us         2.78%            11.056us         11.056us         NaN              0.000us          0.000us          1                []                                   \n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n","Self CPU time total: 397.217us\n","CUDA time total: 0.000us\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"8bto79tYN2kW","colab_type":"text"},"source":["*   otherenv.py"]},{"cell_type":"code","metadata":{"id":"cjwnR8uvNwgC","colab_type":"code","colab":{}},"source":["from scipy.signal import convolve2d, correlate2d\n","from torch.nn.modules.module import Module\n","from torch.nn.parameter import Parameter\n","import torch\n","from torch.autograd import Function\n","from numpy.fft import rfft2, irfft2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vdoWMG_5N_QC","colab_type":"code","colab":{}},"source":["## 파라미터가 없는 신경 네트워크 레이어\n","## NumPy 호출\n","class BadFFTFunction(Function):\n","\n","    def forward(self, input):\n","        numpy_input = input.detach().numpy()\n","        result = abs(rfft2(numpy_input))\n","        return input.new(result)\n","\n","    def backward(self, grad_output):\n","        numpy_go = grad_output.numpy()\n","        result = irfft2(numpy_go)\n","        return grad_output.new(result)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hi_IFNhlN_oL","colab_type":"code","outputId":"63592714-4d3d-4c4f-b8ce-e175f376f7ce","executionInfo":{"status":"ok","timestamp":1576072153953,"user_tz":-540,"elapsed":557,"user":{"displayName":"김기태","photoUrl":"","userId":"05611496824164447321"}},"colab":{"base_uri":"https://localhost:8080/","height":379}},"source":["## 어떠한 파라미터도 가지고 있지 않기 때문에, nn.Module class가 아닌 단순히 함수로 선언 가능\n","def incorrect_fft(input):\n","    return BadFFTFunction()(input)\n","\n","# 생성된 계층 사용\n","input = torch.randn(8, 8, requires_grad=True)\n","result = incorrect_fft(input)\n","print(result)\n","result.backward(torch.randn(result.size()))\n","print(input)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[ 0.7769, 12.4145,  6.1387,  6.8268, 12.2997],\n","        [ 3.5703,  5.9944,  7.1139,  7.9856, 10.8436],\n","        [ 9.0111,  9.9996, 15.4300,  5.8045,  1.6839],\n","        [ 8.8676,  4.6452,  4.1934, 15.6487,  2.6560],\n","        [10.6404,  8.1674,  1.4506,  8.1888,  5.3366],\n","        [ 8.8676,  5.1615,  2.7822,  9.4244,  2.6560],\n","        [ 9.0111,  6.2403,  6.8715,  6.8352,  1.6839],\n","        [ 3.5703, 14.0815,  9.7259,  2.1732, 10.8436]],\n","       grad_fn=<BadFFTFunction>)\n","tensor([[-0.9711, -0.9519,  0.6763,  0.9975,  0.6966,  1.1866,  0.6841,  0.2102],\n","        [-0.3545,  1.2948, -0.5142, -0.5564, -0.6927,  0.8253,  2.1920,  0.6857],\n","        [ 1.1669, -0.3851, -0.5955, -1.0725, -2.2673,  1.2097,  1.7063, -1.4818],\n","        [ 0.6880,  0.3396,  0.5218, -1.5066,  0.5540, -0.4042, -0.6406,  1.0090],\n","        [ 1.3870, -3.2352, -0.1160,  0.1354, -0.1221, -0.7590, -0.1295, -0.7277],\n","        [ 1.5963,  0.5002,  1.5813, -0.6002,  0.0748, -0.3494,  0.5254,  0.9195],\n","        [-0.5071,  0.2542, -1.0777, -1.8808,  1.2063,  0.4239,  0.2059, -0.7985],\n","        [-0.4568, -1.6370, -0.3895, -0.1796, -0.1126,  1.5466,  0.0224, -0.7738]],\n","       requires_grad=True)\n"],"name":"stdout"},{"output_type":"stream","text":["/pytorch/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"g7Q8DgCFOF4K","colab_type":"code","colab":{}},"source":["## 학습 가능한 가중치를 갖는 신경 네트워크 계층 생성\n","## SciPy 호출\n","class ScipyConv2dFunction(Function):\n","    @staticmethod\n","    def forward(ctx, input, filter):\n","        # NumPy에 cast 할 수 있도록 분리\n","        input, filter = input.detach(), filter.detach()\n","        result = correlate2d(input.numpy(), filter.detach().numpy(), mode='valid')\n","        ctx.save_for_backward(input, filter)\n","        return input.new(result)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        grad_output = grad_output.detach()\n","        input, filter = ctx.saved_tensors\n","        grad_input = convolve2d(grad_output.numpy(), filter.t().numpy(), mode='full')\n","        grad_filter = convolve2d(input.numpy(), grad_output.numpy(), mode='valid')\n","\n","        return grad_output.new_tensor(grad_input), grad_output.new_tensor(grad_filter)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7WiHLVsbOKYp","colab_type":"code","colab":{}},"source":["class ScipyConv2d(Module):\n","\n","    def __init__(self, kh, kw):\n","        super(ScipyConv2d, self).__init__()\n","        self.filter = Parameter(torch.randn(kh, kw))\n","\n","    def forward(self, input):\n","        return ScipyConv2dFunction.apply(input, self.filter)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iliqhOp2ORtK","colab_type":"code","outputId":"b11424de-9e63-4d59-8e74-651d970d0dd3","executionInfo":{"status":"ok","timestamp":1576072194567,"user_tz":-540,"elapsed":640,"user":{"displayName":"김기태","photoUrl":"","userId":"05611496824164447321"}},"colab":{"base_uri":"https://localhost:8080/","height":611}},"source":["module = ScipyConv2d(3, 3)\n","print(list(module.parameters()))\n","input = torch.randn(10, 10, requires_grad=True)\n","output = module(input)\n","print(output)\n","output.backward(torch.randn(8, 8))\n","print(input.grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[Parameter containing:\n","tensor([[-1.1066, -0.6778,  1.7192],\n","        [-1.5343, -0.9657, -0.8305],\n","        [-0.1279,  0.4434, -2.3637]], requires_grad=True)]\n","tensor([[ 5.2346,  0.9000,  5.1764, -6.8713,  0.6142,  6.1871,  0.9441, -4.8945],\n","        [-1.9496, -0.0778, -0.4449,  2.5229, -2.5123,  3.4632,  3.8921,  1.8022],\n","        [-1.3675,  0.5252, -6.2152,  2.1431, -0.0800,  0.1739,  1.4143,  0.5641],\n","        [ 0.3921, -0.4304, -5.4476, -3.6244, -0.5503,  3.7724, -1.9953, -4.8017],\n","        [-1.5782, -1.3202,  2.5477, -2.1432, -7.4357,  5.5934, -0.1721, -4.7424],\n","        [ 0.6395,  7.4393,  1.6977, -0.8717, -4.7625, -1.0466,  2.2804,  1.5283],\n","        [-1.7883, -0.2413, -4.7623,  1.7718,  0.5406, -8.3984,  2.9529,  5.1917],\n","        [ 1.2366, -4.8144, -2.1437,  1.2044, -3.1919,  2.3996, -2.4476,  6.8843]],\n","       grad_fn=<ScipyConv2dFunctionBackward>)\n","tensor([[-1.0409e+00, -1.5644e+00,  8.7278e-01,  2.3866e+00,  1.2032e+00,\n","         -1.3906e+00, -1.7672e+00, -3.6139e-02, -2.4886e-01, -2.3036e-02],\n","        [-4.9307e-01,  4.5552e-01,  2.4288e+00,  3.0925e-01, -1.7720e+00,\n","         -2.4369e+00, -1.2098e+00,  3.0352e-01, -1.1693e+00,  2.5489e-03],\n","        [ 2.7736e+00,  1.3509e+00, -4.0161e+00, -1.7111e+00,  2.2909e+00,\n","          3.6516e+00,  3.2921e-01, -1.4294e+00,  4.6238e-01, -9.7101e-02],\n","        [ 1.0512e+00,  5.4786e-01,  1.2263e+00,  4.9224e+00,  2.1045e+00,\n","         -2.0933e+00, -7.8015e-01,  1.2650e+00,  1.4042e+00, -1.5390e+00],\n","        [-1.4698e+00,  7.0973e-01, -2.7453e-01, -2.9413e+00,  3.5973e+00,\n","          1.0517e+00, -4.9750e-01,  1.3114e+00,  2.5035e+00,  7.8089e-01],\n","        [-8.4249e-01, -1.9492e+00, -4.2662e-01, -4.3459e+00, -3.0436e+00,\n","          1.3342e+00,  2.2956e+00, -3.4868e-01, -1.0934e+00,  1.7699e+00],\n","        [ 1.4030e-01,  2.1005e+00, -2.2017e+00, -6.8373e+00, -5.6110e+00,\n","          4.4487e-01,  9.2941e+00,  2.8066e+00, -1.9920e+00,  2.3142e-01],\n","        [-5.7319e-01,  8.3254e-01,  2.1420e+00, -1.6842e-01,  4.9799e+00,\n","          2.8767e+00, -3.1427e-01,  2.7289e+00,  8.4854e-01, -6.6227e-01],\n","        [ 4.6296e-01, -5.8502e-01, -1.4438e-01,  2.5716e+00,  2.9190e+00,\n","         -4.3989e+00,  6.1336e-01,  7.8914e+00,  1.4744e+00, -1.8557e+00],\n","        [ 2.2251e-02, -3.1395e-01,  1.5309e+00, -4.5769e+00, -3.4970e+00,\n","          5.4263e+00,  4.9735e+00,  3.5820e+00,  1.5558e+00,  7.6851e-02]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wwKqKC9yFMce","colab_type":"text"},"source":["*   profile_support.py"]},{"cell_type":"code","metadata":{"id":"L139ktNEBL0l","colab_type":"code","colab":{}},"source":["import time\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0tDWzSuWBf51","colab_type":"code","colab":{}},"source":["input_size = 10\n","epochs = 2\n","batches = 64\n","lr = 0.01"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7efy5v4OBhAE","colab_type":"code","colab":{}},"source":["def encoder(input_size):\n","    def wrapper(num):\n","        ret = [int(i) for i in '{0:b}'.format(num)]\n","        return [0] * (input_size - len(ret)) + ret\n","    return wrapper"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fd8FunLHBipL","colab_type":"code","colab":{}},"source":["def decoder(array):\n","    ret = 0\n","    for i in array:\n","        ret = ret * 2 + int(i)\n","    return ret"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XSHfeHTKBkOk","colab_type":"code","colab":{}},"source":["def training_test_gen(x, y):\n","    assert len(x) == len(y)\n","    indices = np.random.permutation(range(len(x)))\n","    split_size = int(0.9 * len(indices))\n","    trX = x[indices[:split_size]]\n","    trY = y[indices[:split_size]]\n","    teX = x[indices[split_size:]]\n","    teY = y[indices[split_size:]]\n","    return trX, trY, teX, teY"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4OaUPOBNBllY","colab_type":"code","colab":{}},"source":["def get_data(input_size):\n","    x = []\n","    y = []\n","    binary_enc = encoder(input_size)\n","    for i in range(1000):\n","        x.append(binary_enc(i))\n","        if i % 15 == 0:\n","            y.append([1, 0, 0, 0])\n","        elif i % 5 == 0:\n","            y.append([0, 1, 0, 0])\n","        elif i % 3 == 0:\n","            y.append([0, 0, 1, 0])\n","        else:\n","            y.append([0, 0, 0, 1])\n","    return training_test_gen(np.array(x), np.array(y))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"71ie8tapBnN2","colab_type":"code","colab":{}},"source":["def check_fizbuz(i):\n","    if i % 15 == 0:\n","        return 'fizbuz'\n","    elif i % 5 == 0:\n","        return 'buz'\n","    elif i % 3 == 0:\n","        return 'fiz'\n","    else:\n","        return 'number'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTRPCq0BBokU","colab_type":"code","colab":{}},"source":["class FizBuzNet(nn.Module):\n","\n","    def __init__(self, input_size, output_size):\n","        super(FizBuzNet, self).__init__()\n","        # A simple heuristic to find the hiddenlayer size\n","        hidden_size = 100\n","        self.hidden = nn.Linear(input_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, batch):\n","        hidden = self.hidden(batch)\n","        activated = F.sigmoid(hidden)\n","        out = self.out(activated)\n","        return F.sigmoid(out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOocDSOuDPmv","colab_type":"code","outputId":"cc866b76-65d9-4108-e923-b57c366dea8a","executionInfo":{"status":"ok","timestamp":1576072245450,"user_tz":-540,"elapsed":489,"user":{"displayName":"김기태","photoUrl":"","userId":"05611496824164447321"}},"colab":{"base_uri":"https://localhost:8080/","height":721}},"source":["trX, trY, teX, teY = get_data(input_size)\n","if torch.cuda.is_available():\n","    dtype = torch.cuda.FloatTensor\n","else:\n","    dtype = torch.FloatTensor\n","x = torch.from_numpy(trX).type(dtype)\n","y = torch.from_numpy(trY).type(dtype)\n","\n","net = FizBuzNet(input_size, 4)\n","loss_fn = nn.MSELoss()\n","net = net.to(device)\n","optimizer = optim.Adam(net.parameters(), lr=lr)\n","x_ = x[0:10]\n","y_ = y[0:10]\n","hyp = net(x_)\n","\n","print(prof)\n","prof.export_chrome_trace('chrometrace')\n","print(prof.key_averages())\n","print(prof.table('cpu_time'))\n","\n","loss = loss_fn(hyp, y_)\n","loss.backward()\n","optimizer.step()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n","Name                Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  Input Shapes                         \n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n","unsigned short      7.30%            28.984us         7.30%            28.984us         28.984us         NaN              0.000us          0.000us          1                []                                   \n","addmm               45.00%           178.746us        45.00%           178.746us        178.746us        NaN              0.000us          0.000us          1                []                                   \n","sigmoid             19.72%           78.347us         19.72%           78.347us         78.347us         NaN              0.000us          0.000us          1                []                                   \n","unsigned short      2.78%            11.056us         2.78%            11.056us         11.056us         NaN              0.000us          0.000us          1                []                                   \n","addmm               15.15%           60.173us         15.15%           60.173us         60.173us         NaN              0.000us          0.000us          1                []                                   \n","sigmoid             10.05%           39.911us         10.05%           39.911us         39.911us         NaN              0.000us          0.000us          1                []                                   \n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n","Self CPU time total: 397.217us\n","CUDA time total: 0.000us\n","\n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n","Name                Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  \n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n","unsigned short      10.08%           40.040us         10.08%           40.040us         20.020us         NaN              0.000us          0.000us          2                \n","addmm               60.15%           238.919us        60.15%           238.919us        119.460us        NaN              0.000us          0.000us          2                \n","sigmoid             29.77%           118.258us        29.77%           118.258us        59.129us         NaN              0.000us          0.000us          2                \n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n","Self CPU time total: 397.217us\n","CUDA time total: 0.000us\n","\n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n","Name                Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  Input Shapes                         \n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n","addmm               45.00%           178.746us        45.00%           178.746us        178.746us        NaN              0.000us          0.000us          1                []                                   \n","sigmoid             19.72%           78.347us         19.72%           78.347us         78.347us         NaN              0.000us          0.000us          1                []                                   \n","addmm               15.15%           60.173us         15.15%           60.173us         60.173us         NaN              0.000us          0.000us          1                []                                   \n","sigmoid             10.05%           39.911us         10.05%           39.911us         39.911us         NaN              0.000us          0.000us          1                []                                   \n","unsigned short      7.30%            28.984us         7.30%            28.984us         28.984us         NaN              0.000us          0.000us          1                []                                   \n","unsigned short      2.78%            11.056us         2.78%            11.056us         11.056us         NaN              0.000us          0.000us          1                []                                   \n","------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  -----------------------------------  \n","Self CPU time total: 397.217us\n","CUDA time total: 0.000us\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"cOP4O67EDYKN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}